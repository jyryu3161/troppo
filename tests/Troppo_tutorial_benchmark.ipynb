{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Troppo 방법론 벤치마크 튜토리얼\n",
    "# Troppo Method Benchmark Tutorial\n",
    "\n",
    "이 튜토리얼은 Troppo의 벤치마크 프레임워크를 사용하여 여러 오믹스 통합 방법론을 비교하는 방법을 보여줍니다.\n",
    "\n",
    "This tutorial demonstrates how to use Troppo's benchmark framework to compare multiple omics integration methods.\n",
    "\n",
    "## 목차 (Contents)\n",
    "\n",
    "1. [기본 벤치마크](#basic)\n",
    "2. [상세 벤치마크 with 검증](#detailed)\n",
    "3. [결과 시각화](#visualization)\n",
    "4. [커스텀 설정](#custom)\n",
    "5. [레포트 생성](#report)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 설정 (Setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cobra\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Troppo imports\n",
    "from troppo.omics.readers.generic import TabularReader\n",
    "from troppo.methods_wrappers import ModelBasedWrapper\n",
    "from troppo.methods.registry import MethodRegistry\n",
    "from troppo.benchmark import BenchmarkRunner, quick_benchmark\n",
    "from troppo.benchmark.visualization import (\n",
    "    plot_performance_comparison,\n",
    "    plot_overlap_heatmap,\n",
    "    plot_pareto_front,\n",
    "    plot_radar_chart,\n",
    "    create_comparison_report\n",
    ")\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 등록된 방법론 확인 (Check Registered Methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 등록된 모든 방법론 확인\n",
    "print(\"Available methods:\")\n",
    "for method in MethodRegistry.list_methods():\n",
    "    print(f\"  - {method}\")\n",
    "\n",
    "print(\"\\nDetailed registry:\")\n",
    "MethodRegistry.print_registry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 로드 (Load Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPR parsing function\n",
    "patt = re.compile('__COBAMPGPRDOT__[0-9]{1}')\n",
    "replace_alt_transcripts = lambda x: patt.sub('', x)\n",
    "\n",
    "# Load model\n",
    "model_path = 'data/HumanGEM_Consistent_COVID19_HAM.xml'\n",
    "model = cobra.io.read_sbml_model(model_path)\n",
    "print(f\"Model loaded: {len(model.reactions)} reactions, {len(model.metabolites)} metabolites\")\n",
    "\n",
    "# Load omics data\n",
    "omics_data_path = 'data/Desai-GTEx_ensembl.csv'\n",
    "omics_data = pd.read_csv(filepath_or_buffer=omics_data_path, index_col=0)\n",
    "print(f\"Omics data loaded: {omics_data.shape[0]} samples, {omics_data.shape[1]} genes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리 (Preprocess Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create omics container\n",
    "reader = TabularReader(\n",
    "    path_or_df=omics_data,\n",
    "    nomenclature='ensemble_gene_id',\n",
    "    omics_type='transcriptomics'\n",
    ")\n",
    "omics_container = reader.to_containers()[0]\n",
    "print(f\"OmicsContainer created: {len(omics_container.get_Data())} genes\")\n",
    "\n",
    "# Create model wrapper\n",
    "model_wrapper = ModelBasedWrapper(\n",
    "    model=model,\n",
    "    ttg_ratio=9999,\n",
    "    gpr_gene_parse_function=replace_alt_transcripts\n",
    ")\n",
    "print(f\"ModelWrapper created: {len(model_wrapper.model_reader.r_ids)} reactions\")\n",
    "\n",
    "# Map genes to reactions\n",
    "data_map = omics_container.get_integrated_data_map(\n",
    "    model_reader=model_wrapper.model_reader,\n",
    "    and_func=min,\n",
    "    or_func=sum\n",
    ")\n",
    "print(f\"Gene-Reaction mapping complete: {len(data_map.get_scores())} scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. 빠른 벤치마크 (Quick Benchmark) {#basic}\n",
    "\n",
    "가장 간단한 방법으로 모든 방법론을 비교합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick benchmark - returns summary dataframe\n",
    "summary_df = quick_benchmark(\n",
    "    model_wrapper=model_wrapper,\n",
    "    data_map=data_map,\n",
    "    methods=['gimme', 'tinit', 'imat', 'fastcore'],\n",
    "    biomass_reaction='biomass_human',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BENCHMARK SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(summary_df)\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. 상세 벤치마크 (Detailed Benchmark) {#detailed}\n",
    "\n",
    "생물학적 검증과 일관성 체크를 포함한 상세 벤치마크입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create benchmark runner\n",
    "runner = BenchmarkRunner(\n",
    "    model_wrapper=model_wrapper,\n",
    "    data_map=data_map,\n",
    "    methods=['gimme', 'tinit', 'imat', 'fastcore'],\n",
    "    biomass_reaction='biomass_human',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Run with validation\n",
    "comparison = runner.run_benchmark(\n",
    "    validate_biology=True,\n",
    "    validate_consistency=True\n",
    ")\n",
    "\n",
    "print(\"\\nBenchmark completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과 분석 (Result Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table\n",
    "print(\"Performance Summary:\")\n",
    "print(comparison.get_summary_dataframe())\n",
    "\n",
    "# Overlap matrix\n",
    "print(\"\\nReaction Overlap Matrix (Jaccard Similarity):\")\n",
    "print(comparison.get_overlap_matrix())\n",
    "\n",
    "# Common reactions\n",
    "common_rxns = comparison.get_common_reactions()\n",
    "print(f\"\\nReactions common to all methods: {len(common_rxns)}\")\n",
    "\n",
    "# Unique reactions per method\n",
    "print(\"\\nUnique reactions by method:\")\n",
    "for method in comparison.results.keys():\n",
    "    unique = comparison.get_unique_reactions(method)\n",
    "    print(f\"  {method}: {len(unique)} unique reactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 방법론 순위 (Method Rankings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank by different metrics\n",
    "metrics = ['execution_time', 'peak_memory', 'percentage_retained']\n",
    "\n",
    "for metric in metrics:\n",
    "    print(f\"\\nRanking by {metric}:\")\n",
    "    rankings = comparison.rank_methods(metric)\n",
    "    for rank, (method, value) in enumerate(rankings, 1):\n",
    "        print(f\"  {rank}. {method}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. 결과 시각화 (Visualization) {#visualization}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Comparison Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance_comparison(\n",
    "    comparison,\n",
    "    metrics=['execution_time', 'peak_memory', 'percentage_retained', 'biomass_flux'],\n",
    "    figsize=(15, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlap Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_overlap_heatmap(comparison, figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pareto Front (Trade-off Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time vs Performance trade-off\n",
    "plot_pareto_front(\n",
    "    comparison,\n",
    "    x_metric='execution_time',\n",
    "    y_metric='percentage_retained',\n",
    "    figsize=(10, 6)\n",
    ")\n",
    "\n",
    "# Memory vs Performance trade-off\n",
    "plot_pareto_front(\n",
    "    comparison,\n",
    "    x_metric='peak_memory',\n",
    "    y_metric='biomass_flux',\n",
    "    figsize=(10, 6)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radar Chart (Multi-metric Comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_radar_chart(\n",
    "    comparison,\n",
    "    metrics=['execution_time', 'peak_memory', 'percentage_retained', 'biomass_flux'],\n",
    "    normalize=True,\n",
    "    figsize=(10, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. 커스텀 설정 (Custom Configuration) {#custom}\n",
    "\n",
    "각 방법론에 대한 커스텀 파라미터를 지정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define method-specific configurations\n",
    "method_configs = {\n",
    "    'gimme': {\n",
    "        'obj_frac': 0.9,  # More strict objective fraction\n",
    "        'flux_threshold': 0.9,\n",
    "        'preprocess': True\n",
    "    },\n",
    "    'tinit': {\n",
    "        'threshold': np.percentile(\n",
    "            [v for v in data_map.get_scores().values() if v is not None],\n",
    "            80  # Top 20% instead of 25%\n",
    "        )\n",
    "    },\n",
    "    'imat': {\n",
    "        'high_threshold': np.percentile(\n",
    "            [v for v in data_map.get_scores().values() if v is not None],\n",
    "            75  # Adjusted thresholds\n",
    "        ),\n",
    "        'low_threshold': np.percentile(\n",
    "            [v for v in data_map.get_scores().values() if v is not None],\n",
    "            25\n",
    "        ),\n",
    "        'epsilon': 0.5\n",
    "    }\n",
    "}\n",
    "\n",
    "# Run with custom configs\n",
    "runner_custom = BenchmarkRunner(\n",
    "    model_wrapper=model_wrapper,\n",
    "    data_map=data_map,\n",
    "    methods=['gimme', 'tinit', 'imat'],\n",
    "    biomass_reaction='biomass_human',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "comparison_custom = runner_custom.run_benchmark(\n",
    "    method_configs=method_configs,\n",
    "    validate_biology=True\n",
    ")\n",
    "\n",
    "print(\"\\nCustom configuration results:\")\n",
    "print(comparison_custom.get_summary_dataframe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. 종합 레포트 생성 (Generate Comprehensive Report) {#report}\n",
    "\n",
    "모든 결과를 포함하는 종합 레포트를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive report\n",
    "create_comparison_report(\n",
    "    comparison,\n",
    "    output_dir='benchmark_results',\n",
    "    include_plots=True\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Report generated in 'benchmark_results' directory\")\n",
    "print(\"\\nGenerated files:\")\n",
    "print(\"  - benchmark_summary_*.csv\")\n",
    "print(\"  - overlap_matrix_*.csv\")\n",
    "print(\"  - benchmark_results_*.json\")\n",
    "print(\"  - performance_comparison_*.png\")\n",
    "print(\"  - overlap_heatmap_*.png\")\n",
    "print(\"  - pareto_front_*.png\")\n",
    "print(\"  - radar_chart_*.png\")\n",
    "print(\"  - benchmark_report_*.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과 저장 및 불러오기 (Save and Load Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to JSON\n",
    "comparison.save_to_json('my_benchmark_results.json')\n",
    "print(\"Results saved to my_benchmark_results.json\")\n",
    "\n",
    "# Load results later\n",
    "from troppo.benchmark import BenchmarkComparison\n",
    "loaded_comparison = BenchmarkComparison.load_from_json('my_benchmark_results.json')\n",
    "print(\"\\nResults loaded successfully!\")\n",
    "print(loaded_comparison.get_summary_dataframe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 추가: 개별 방법 상세 분석 (Individual Method Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze a specific method in detail\n",
    "method_name = 'gimme'\n",
    "\n",
    "if method_name in comparison.results:\n",
    "    result = comparison.results[method_name]\n",
    "    \n",
    "    print(f\"\\nDetailed Analysis: {method_name.upper()}\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Execution Time: {result.execution_time:.2f} seconds\")\n",
    "    print(f\"Peak Memory: {result.peak_memory:.2f} MB\")\n",
    "    print(f\"Reactions Selected: {result.num_reactions_selected}\")\n",
    "    print(f\"Percentage Retained: {result.percentage_retained:.2f}%\")\n",
    "    \n",
    "    if result.biomass_flux is not None:\n",
    "        print(f\"Biomass Flux: {result.biomass_flux:.4f}\")\n",
    "    \n",
    "    if result.num_blocked_reactions is not None:\n",
    "        print(f\"Blocked Reactions: {result.num_blocked_reactions}\")\n",
    "    \n",
    "    # Show some selected reactions\n",
    "    print(f\"\\nSample of selected reactions (first 10):\")\n",
    "    for rxn_id in result.selected_reaction_ids[:10]:\n",
    "        print(f\"  - {rxn_id}\")\n",
    "    \n",
    "    # Unique reactions\n",
    "    unique = comparison.get_unique_reactions(method_name)\n",
    "    print(f\"\\nReactions unique to {method_name}: {len(unique)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 요약 (Summary)\n",
    "\n",
    "이 튜토리얼에서 다룬 내용:\n",
    "\n",
    "1. **빠른 벤치마크**: `quick_benchmark()` 함수로 간단하게 비교\n",
    "2. **상세 벤치마크**: `BenchmarkRunner`로 생물학적 검증 포함\n",
    "3. **시각화**: 다양한 차트로 결과 비교\n",
    "4. **커스텀 설정**: 방법론별 파라미터 조정\n",
    "5. **레포트 생성**: 종합 레포트 자동 생성\n",
    "\n",
    "### 주요 기능:\n",
    "\n",
    "- ✅ 여러 방법론 동시 비교\n",
    "- ✅ 성능 지표 자동 수집 (시간, 메모리, 모델 크기)\n",
    "- ✅ 생물학적 검증 (biomass flux, task completion)\n",
    "- ✅ 네트워크 일관성 체크\n",
    "- ✅ 반응 중복 분석\n",
    "- ✅ 다양한 시각화\n",
    "- ✅ 자동 레포트 생성\n",
    "\n",
    "---\n",
    "\n",
    "**For more information:**\n",
    "- Troppo Documentation: http://troppo-bisbi.readthedocs.io/\n",
    "- GitHub: https://github.com/BioSystemsUM/troppo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
